import React, { useRef, useEffect, useState, useCallback } from 'react';
import { ProcessingOptions, ProcessingStatus } from '../types';

interface ProcessorProps {
  file: File;
  options: ProcessingOptions;
  status: ProcessingStatus;
  setStatus: (status: ProcessingStatus) => void;
}

const Processor: React.FC<ProcessorProps> = ({ file, options, status, setStatus }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [videoSrc, setVideoSrc] = useState<string>("");
  const [downloadUrl, setDownloadUrl] = useState<string | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const requestRef = useRef<number>();

  // Initialize video source
  useEffect(() => {
    const url = URL.createObjectURL(file);
    setVideoSrc(url);
    return () => URL.revokeObjectURL(url);
  }, [file]);

  const stopProcessing = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }
    if (requestRef.current) {
      cancelAnimationFrame(requestRef.current);
    }
  }, []);

  const startProcessing = useCallback(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    
    if (!video || !canvas) return;

    setStatus(ProcessingStatus.PROCESSING);
    setDownloadUrl(null);
    recordedChunksRef.current = [];

    // Setup Canvas Dimensions
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    
    const ctx = canvas.getContext('2d', { 
      alpha: false, // Optimize for no transparency in output
      desynchronized: true 
    });
    
    if (!ctx) {
      alert("Canvas context initialization failed");
      setStatus(ProcessingStatus.ERROR);
      return;
    }

    // Reset Canvas to black
    ctx.fillStyle = '#000000';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    // Setup MediaRecorder
    const stream = canvas.captureStream(options.fps);
    
    // Choose the best supported mime type
    const mimeTypes = [
      'video/webm;codecs=vp9',
      'video/webm;codecs=vp8',
      'video/webm'
    ];
    let selectedMimeType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type)) || '';

    try {
      // Need a higher bitrate for high FPS to look decent
      const bitrate = options.fps > 60 ? 8000000 : 5000000; 
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
        videoBitsPerSecond: bitrate
      });
    } catch (e) {
      console.error("MediaRecorder init failed", e);
      // Fallback without options
      mediaRecorderRef.current = new MediaRecorder(stream);
    }

    mediaRecorderRef.current.ondataavailable = (event) => {
      if (event.data.size > 0) {
        recordedChunksRef.current.push(event.data);
      }
    };

    mediaRecorderRef.current.onstop = () => {
      const blob = new Blob(recordedChunksRef.current, { type: 'video/webm' });
      const url = URL.createObjectURL(blob);
      setDownloadUrl(url);
      setStatus(ProcessingStatus.COMPLETED);
    };

    // Processing Logic
    // Motion Blur Logic: Draw new frame with opacity. 
    // High opacity = Less Blur (Previous frames disappear quickly)
    // Low opacity = High Blur (Previous frames stick around)
    // User Input: Blur Strength (0 - 100).
    // Strength 0 -> alpha 1.0 (No blur, instant replace)
    // Strength 90 -> alpha 0.1 (Heavy trails)
    const alpha = Math.max(0.01, 1 - (options.blurStrength / 100));

    // Reset video to start
    video.currentTime = 0;
    
    // Use requestVideoFrameCallback if available for precise frame syncing, otherwise RAF
    const playAndRecord = async () => {
      mediaRecorderRef.current?.start();
      try {
        await video.play();
      } catch (err) {
        console.error("Play failed", err);
        setStatus(ProcessingStatus.ERROR);
        return;
      }

      const drawFrame = () => {
        if (video.paused || video.ended) {
          stopProcessing();
          return;
        }

        // Draw the current video frame on top of the existing canvas content
        // using the calculated alpha to create the trail effect.
        ctx.globalAlpha = alpha;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        // Restore alpha for safety if we did other drawing
        ctx.globalAlpha = 1.0;

        if ('requestVideoFrameCallback' in video) {
          video.requestVideoFrameCallback(drawFrame);
        } else {
          requestRef.current = requestAnimationFrame(drawFrame);
        }
      };

      if ('requestVideoFrameCallback' in video) {
        video.requestVideoFrameCallback(drawFrame);
      } else {
        requestRef.current = requestAnimationFrame(drawFrame);
      }
    };

    playAndRecord();

  }, [file, options, setStatus, stopProcessing]);


  // Watch for external status changes or cleanup
  useEffect(() => {
    if (status === ProcessingStatus.PROCESSING && !mediaRecorderRef.current) {
        startProcessing();
    }
  }, [status, startProcessing]);

  return (
    <div className="w-full space-y-4">
      <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
        {/* Original Source (Hidden during processing to save resources, or shown small) */}
        <div className="bg-slate-900 rounded-lg overflow-hidden border border-slate-700 relative aspect-video">
           <div className="absolute top-2 left-2 bg-black/60 px-2 py-1 rounded text-xs text-white z-10">オリジナル (プレビュー)</div>
          <video
            ref={videoRef}
            src={videoSrc}
            className="w-full h-full object-contain"
            muted
            playsInline
            onEnded={() => {
                if(status === ProcessingStatus.PROCESSING) {
                    stopProcessing();
                }
            }}
            controls={status !== ProcessingStatus.PROCESSING}
          />
        </div>

        {/* Output Canvas */}
        <div className="bg-slate-900 rounded-lg overflow-hidden border border-slate-700 relative aspect-video">
           <div className="absolute top-2 left-2 bg-blue-600/80 px-2 py-1 rounded text-xs text-white z-10">
             {status === ProcessingStatus.PROCESSING ? '処理中 & 録画中...' : '出力結果'}
           </div>
          <canvas
            ref={canvasRef}
            className="w-full h-full object-contain bg-black"
          />
        </div>
      </div>

      {status === ProcessingStatus.COMPLETED && downloadUrl && (
        <div className="bg-green-500/10 border border-green-500/50 p-4 rounded-xl flex flex-col md:flex-row items-center justify-between gap-4 animate-fade-in">
           <div className="flex items-center gap-3">
             <div className="bg-green-500 rounded-full p-2">
               <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                 <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
               </svg>
             </div>
             <div>
               <h4 className="font-bold text-green-400">処理完了！</h4>
               <p className="text-sm text-green-300/80">動画の生成が完了しました。</p>
             </div>
           </div>
           
           <a
             href={downloadUrl}
             download={`motion-blur-${options.fps}fps-${Date.now()}.webm`}
             className="px-6 py-3 bg-green-600 hover:bg-green-500 text-white font-bold rounded-lg shadow-lg shadow-green-500/30 transition-all flex items-center gap-2"
           >
             <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
               <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4" />
             </svg>
             ダウンロード (WebM)
           </a>
        </div>
      )}
    </div>
  );
};

export default Processor;
